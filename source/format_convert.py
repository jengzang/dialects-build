# -*- coding: utf-8 -*-

"""
æœ¬è…³æœ¬å°‡æ•´åˆéŸ³å…¸ã€è·³è·³è€é¼ ã€ç¸£å¿—ä¸‰ç¨®æ ¼å¼çš„å®Œæ•´å­—è¡¨æå–é‚è¼¯ï¼Œ
æ”¯æ´ .tsvã€.xlsxã€.xlsã€.docx æ ¼å¼
æ ¹æ“šé è¨­è¡¨æˆ–ç”¨æˆ¶é¸æ“‡å°æ‡‰æ ¼å¼ï¼Œè½‰æ›ç‚º #æ¼¢å­— éŸ³æ¨™ è§£é‡‹ çš„ .tsv æ–‡ä»¶ã€‚
"""

import csv
import os
import re
from itertools import product

import docx
import pandas as pd
from docx import Document
from docx.table import Table
from docx.text.paragraph import Paragraph
from openpyxl import load_workbook
from xlrd import open_workbook

from common.config import WRITE_ERROR_LOG
from common.constants import col_map
from common.s2t import s2t_pro


# def get_tsv_name(path):
#     return os.path.splitext(path)[0] + ".tsv"

def get_tsv_name(xls):
    name = os.path.basename(xls)
    name = re.sub(r" ?(\(\d{0,3}\))+$", "", name.rsplit(".", 1)[0]) + ".tsv"
    return os.path.join(os.path.dirname(__file__), name)


def xls_to_tsv(xls_path, page=0):
    def is_xls(fname):
        return fname.endswith("xls") or fname.endswith("xlsx")

    def process_fs(v):
        t = type(v)
        if t is float or t is int:
            return "%d" % v
        if v is None:
            return ""
        return str(v).strip().replace("\t", " ").replace("\n", " ")

    def process_xlsx_fs(v):
        t = type(v)
        if t is float or t is int:
            return "%d" % v
        if v is None:
            return ""
        if t is str:
            return v.strip().replace("\t", " ").replace("\n", " ")
        cells = []
        for i in v:
            if isinstance(i, str):
                cells.append(i.strip())
                continue
            if isinstance(i, (int, float)):
                cells.append("%d" % i)
                continue
            text = i.text
            tag = ""
            if i.font.underline == "single":
                tag = "-"
            elif i.font.underline == "double":
                tag = "="
            if tag:
                text = "".join([j + tag for j in text])
            if i.font.vertAlign == "subscript" or (i.font.size and i.font.size < 10.0):
                text = f"({text})"
            cells.append(text)
        return "".join(cells).replace(")(", "").strip()

    def get_tsv_name(path):
        return os.path.splitext(path)[0] + ".tsv"

    print(f"[INFO] Starting conversion: {xls_path}")
    if not os.path.exists(xls_path):
        print(f"[ERROR] File does not exist: {xls_path}")
        return

    tsv_path = get_tsv_name(xls_path)
    print(f"[INFO] Target TSV path: {tsv_path}")

    lines = []
    header_written = False
    num_columns = 0

    if xls_path.endswith(".xlsx"):
        print("[INFO] Detected .xlsx file")
        wb = load_workbook(xls_path, data_only=True, rich_text=True)
        sheet = wb.worksheets[page]
        print(f"[INFO] Loaded worksheet: {sheet.title}")
        for row_idx, row in enumerate(sheet.rows):
            cols = [process_xlsx_fs(cell.value) for cell in row[:50]]
            if any(cols):
                if not header_written:
                    num_columns = len(cols)
                    header_written = True
                cols += [""] * (num_columns - len(cols))
                lines.append("\t".join(cols[:num_columns]) + "\n")
    else:
        print("[INFO] Detected .xls file")
        wb = open_workbook(xls_path)
        sheet = wb.sheet_by_index(page)
        print(f"[INFO] Loaded sheet: {sheet.name}")
        for i in range(sheet.nrows):
            row = sheet.row_values(i)
            cols = [process_fs(cell) for cell in row]
            if any(cols):
                if not header_written:
                    num_columns = len(cols)
                    header_written = True
                cols += [""] * (num_columns - len(cols))
                lines.append("\t".join(cols[:num_columns]) + "\n")

    print(f"[INFO] Writing {len(lines)} rows to TSV")
    with open(tsv_path, "w", encoding="utf-8", newline="\n") as f:
        f.writelines(lines)

    print(f"[INFO] Conversion complete: {tsv_path}")
    return tsv_path


def run2text(run):
    if isinstance(run, docx.text.hyperlink.Hyperlink):
        return "".join(map(run2text, run.runs))
    tag = ""
    if run.font.underline == docx.enum.text.WD_UNDERLINE.SINGLE:
        tag = "-"
    elif run.font.underline == docx.enum.text.WD_UNDERLINE.DOUBLE:
        tag = "="
    elif run.font.underline == docx.enum.text.WD_UNDERLINE.WAVY:
        tag = chr(0x1AB6)
    elif run._r.xpath("*/w:em[@w:val='dot']"):
        tag = chr(0x0323)
    text = run.text
    if tag:
        text = "".join([i + tag for i in text])
    if run.font.subscript or (run.font.size and run.font.size < docx.shared.Pt(9)):
        if text.startswith("{") and text.endswith("}"):
            pass
        elif text.startswith("[") and text.endswith("]"):
            pass
        else:
            text = f"{{{text}}}"
    return text


def docx_to_tsv(doc):
    if not os.path.exists(doc):
        print("âŒ è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨ï¼Œè·³é")
        return

    lines = []
    Doc = Document(doc)

    for idx, each in enumerate(Doc._body._element):
        if isinstance(each, docx.oxml.table.CT_Tbl):
            # print(f"[ğŸ“] è™•ç†è¡¨æ ¼ ç¬¬ {idx + 1} å€å¡Š")
            t = Table(each, Doc)
            for row_num, row in enumerate(t.rows):
                è¡Œ = ""
                cells = row.cells
                for i, cell in enumerate(cells):
                    if cell in cells[:i]: continue
                    for p in cell.paragraphs:
                        raw = "".join(map(run2text, p.iter_inner_content()))
                        è¡Œ += raw.replace("\t", "").replace("\n", "")
                è¡Œ += "\t"

                before = è¡Œ
                after = è¡Œ.replace("}~", "~}").replace("~{", "{~").replace("}{", "").replace("[}", "}[").replace("{h}",
                                                                                                                 "h").strip()
                # print(f"  [â†’ è¡¨æ ¼ç¬¬ {row_num + 1} è¡Œ] åŸå§‹ï¼š{before}")
                # print(f"  [âœ“ æ¸…æ´—å¾Œ]ï¼š{after}")
                lines.append(after)

        elif isinstance(each, docx.oxml.text.paragraph.CT_P):
            # print(f"[ğŸ“„] è™•ç†æ®µè½ ç¬¬ {idx + 1} å€å¡Š")
            element = Paragraph(each, Doc)
            raw = "".join(map(run2text, element.iter_inner_content()))
            before = raw
            after = raw.replace("}~", "~}").replace("~{", "{~").replace("}{", "").replace("[}", "}[").replace("{h}",
                                                                                                              "h")
            # print(f"  [â†’ æ®µè½åŸå§‹]ï¼š{before}")
            # print(f"  [âœ“ æ¸…æ´—å¾Œ]ï¼š{after}")
            lines.append(after)
    è¡Œ = "\n".join(lines).replace("}\n{", "").replace("\n}", "}\n")
    # print(f"[ğŸ“¦] åˆä½µæ‰€æœ‰è¡Œå¾Œå…§å®¹ é ­ 200 å­—é è¦½ï¼š\n{è¡Œ[:200]}...")
    dirpath = os.path.dirname(doc)
    basename = os.path.splitext(os.path.basename(doc))[0]
    tsv_path = os.path.join(dirpath, basename + ".tsv")
    with open(tsv_path, "w", encoding="utf-8", newline="\n") as t:
        t.write(è¡Œ)
        print(f"[âœ…] å·²å¯«å…¥ï¼š{tsv_path}")

    return tsv_path


def convert_to_tsv_if_needed(filepath):
    ext = os.path.splitext(filepath)[1].lower()
    if ext in [".xlsx", ".xls"]:
        # wb = load_workbook(filepath, data_only=True)
        # sheet = wb.active
        # lines = []
        # for row in sheet.iter_rows(values_only=True):
        #     if all(cell is None for cell in row): continue
        #     line = "\t".join([str(cell).strip() if cell is not None else "" for cell in row])
        #     lines.append(line + "\n")
        # tsv_path = get_tsv_name(filepath)
        # with open(tsv_path, "w", encoding="utf-8") as f:
        #     f.writelines(lines)
        # return tsv_path
        return xls_to_tsv(filepath)
    elif ext == ".docx":
        return docx_to_tsv(filepath)
    else:
        return filepath


# ========== éŸ³å…¸æ ¼å¼è™•ç† ==========
def process_éŸ³å…¸(file, level=1, output_path=None):
    print(f"[é–‹å§‹] è™•ç†æª”æ¡ˆï¼š{file}")

    # cc = OpenCC('s2t' if level == 1 else 't2s')
    # def s2t(text):
    #     return cc.convert(text)

    file = convert_to_tsv_if_needed(file)
    print(f"[è½‰æ›] è½‰ç‚º TSV è·¯å¾‘ï¼š{file}")

    rows = []
    simplified_rows = []

    with open(file, encoding="utf-8") as f:
        lines = [line.rstrip("\n").split("\t") for line in f if line.strip() and not line.startswith("#")]

    if not lines:
        print("âš ï¸ ç„¡æœ‰æ•ˆæ•¸æ“šï¼Œæª”æ¡ˆå…§å®¹ç‚ºç©ºæˆ–æ ¼å¼éŒ¯èª¤")
        with open(WRITE_ERROR_LOG, "a", encoding="utf-8") as f:
            f.write(f"âš ï¸ [{file}] ç„¡æœ‰æ•ˆæ•¸æ“šï¼Œæª”æ¡ˆå…§å®¹ç‚ºç©ºæˆ–æ ¼å¼éŒ¯èª¤\tã€format_convert->process_éŸ³å…¸ã€‘\n")
        return

    header = lines[0]
    print(f"[åˆ†æ] è¡¨é ­ï¼š{header}")

    index = {}
    for std_key, aliases in col_map.items():
        for i, name in enumerate(header):
            if name.strip().lower() in [a.lower() for a in aliases]:
                index[std_key] = i
                print(f"âœ… æ¬„ä½å°æ‡‰ï¼š{std_key} â†’ ç¬¬ {i + 1} æ¬„ï¼ˆ{name}ï¼‰")
                break

    if 'æ¼¢å­—' not in index or 'éŸ³æ¨™' not in index:
        print("âŒ æ¬„ä½å°æ‡‰å¤±æ•—ï¼Œè«‹ç¢ºèªæœ‰ã€æ¼¢å­—ã€èˆ‡ã€éŸ³æ¨™ã€æ¬„ä½")
        with open(WRITE_ERROR_LOG, "a", encoding="utf-8") as f:
            f.write(f"âŒ [{file}]æ¬„ä½å°æ‡‰å¤±æ•—ï¼Œè«‹ç¢ºèªæœ‰ã€æ¼¢å­—ã€èˆ‡ã€éŸ³æ¨™ã€æ¬„ä½\tã€format_convert->process_éŸ³å…¸ã€‘\n")
        return

    print(f"[è™•ç†] é–‹å§‹æƒæè³‡æ–™è¡Œï¼Œå…± {len(lines) - 1} ç­†")

    delimiters = [';', 'ï¼›', '/', 'ã€', ',', 'ï¼Œ']

    def split_field(field):
        for delim in delimiters:
            field = field.replace(delim, 'âˆ¥')  # çµ±ä¸€åˆ†éš”ç¬¦ç‚º âˆ¥
        return [f.strip() for f in field.split('âˆ¥') if f.strip()]

    def get_field(parts, field_name):
        idx = index.get(field_name)
        if idx is not None and idx < len(parts):
            return parts[idx].strip()
        return ""

    def process_pair(word, phon, note, row_num):
        clean_str, mapping = s2t_pro(word, level)
        mapping = dict(mapping)
        phon_units = phon.strip().split()
        word_len_match = len(word) == len(phon_units)

        if word_len_match:
            for ch, p in zip(word, phon_units):
                candidates = mapping.get(ch, [ch])
                for cand in candidates:
                    rows.append([cand, p, note])
                    if cand != ch:
                        simplified_rows.append([cand, p, note, "ç°¡"])
                        print(f"[ç°¡é«”ä¸€å°å¤š] ç¬¬ {row_num} è¡Œï¼š{ch} â†’ {cand}")
        else:
            rows.append([clean_str, phon, note])
            if clean_str != word:
                simplified_rows.append([clean_str, phon, note, "ç°¡"])
                print(f"[fallback] ç¬¬ {row_num} è¡Œï¼š{word} â†’ {clean_str}")

    print(f"[è™•ç†] é–‹å§‹æƒæè³‡æ–™è¡Œï¼Œå…± {len(lines) - 1} ç­†")

    for row_num, parts in enumerate(lines[1:], start=2):
        word_raw = get_field(parts, 'æ¼¢å­—')
        phon_raw = get_field(parts, 'éŸ³æ¨™')
        note = get_field(parts, 'è§£é‡‹')

        if not word_raw or not phon_raw:
            continue

        word_list = split_field(word_raw)
        phon_list = split_field(phon_raw)

        if not word_list or not phon_list:
            print(f"âš ï¸ è·³éç¬¬ {row_num} è¡Œï¼Œå› ç‚ºæ¼¢å­—æˆ–éŸ³æ¨™æ¸…å–®ç‚ºç©º")
            continue

        if len(word_list) > 1 and len(phon_list) > 1:
            # âœ… ç„¡è«–ç­‰é•·èˆ‡å¦ï¼Œå§‹çµ‚åšç¬›å¡çˆ¾ç©
            print(f"[ç¬›å¡çˆ¾ç©] ç¬¬ {row_num} è¡Œï¼š{word_list} Ã— {phon_list}")
            for word, phon in product(word_list, phon_list):
                process_pair(word, phon, note, row_num)

        elif len(word_list) > 1 and len(phon_list) == 1:
            # âœ… å¤šå°ä¸€
            print(f"[å¤šå°ä¸€] ç¬¬ {row_num} è¡Œï¼š{word_list} Ã— {phon_list[0]}")
            for word in word_list:
                process_pair(word, phon_list[0], note, row_num)

        elif len(word_list) == 1 and len(phon_list) > 1:
            # âœ… ä¸€å°å¤š
            print(f"[ä¸€å°å¤š] ç¬¬ {row_num} è¡Œï¼š{word_list[0]} Ã— {phon_list}")
            for phon in phon_list:
                process_pair(word_list[0], phon, note, row_num)

        else:
            # fallback åˆä½µè™•ç†
            word = ''.join(word_list)
            phon = ' '.join(phon_list)
            # print(f"[fallback] ç¬¬ {row_num} è¡Œï¼š{word} â†’ {phon}")
            process_pair(word, phon, note, row_num)

    outpath = output_path or (os.path.splitext(file)[0] + ".tsv")
    print(f"[è¼¸å‡º] å¯«å…¥ä¸»æª”æ¡ˆï¼š{outpath}")

    with open(outpath, "w", encoding="utf-8", newline="\n") as out:
        writer = csv.writer(out, delimiter="\t")
        writer.writerow(["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹"])
        writer.writerows(rows)

    # simp_path = os.path.splitext(file)[0] + ".ç°¡.tsv"
    # if simplified_rows:
    #     print(f"[ç°¡é«”] å…±ç™¼ç¾ {len(simplified_rows)} ç­†ç°¡é«”è©å½™ï¼Œå¯«å…¥ï¼š{simp_path}")
    #     with open(simp_path, "w", encoding="utf-8", newline="\n") as out:
    #         writer = csv.writer(out, delimiter="\t")
    #         writer.writerow(["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹", "ç¹ç°¡"])
    #         writer.writerows(simplified_rows)

    print(f"âœ… å…¨éƒ¨è™•ç†å®Œæˆï¼š{outpath}")


# ========== è·³è·³è€é¼ æ ¼å¼è™•ç† ==========
def process_è·³è·³è€é¼ (file, level=1, output_path=None):
    print(f"ğŸ“„ é–‹å§‹è™•ç†æ–‡ä»¶ï¼š{file}")
    rows = []
    simplified_rows = []

    # é¸æ“‡ç¹â†’ç°¡æˆ–ç°¡â†’ç¹
    # converter = OpenCC('s2t' if level == 1 else 't2s')
    # def s2t(text):
    #     return converter.convert(text)

    # è®€å– Excelï¼ˆåƒ…ç¬¬ä¸€å¼µè¡¨ï¼‰
    wb = load_workbook(file, data_only=True)
    sheet = wb.active

    def parse_row(line, line_num):
        parts = [str(c).strip() if c is not None else "" for c in line]
        if len(parts) < 2:
            print(f"âš ï¸ ç¬¬ {line_num} è¡Œæ¬„ä½ä¸è¶³ï¼Œè·³éï¼š{parts}")
            return []
        phon = parts[0]
        çµ„ = parts[1]
        if not phon or not çµ„:
            print(f"âš ï¸ ç¬¬ {line_num} è¡Œç¼ºéŸ³æˆ–å­—ï¼Œè·³é")
            return []
        result = []
        matches = re.findall(r"(.)(?:\{(.*?)\}|\[(.*?)\])?", çµ„)
        print(f"ğŸ” ç¬¬ {line_num} è¡Œçµ„æ‹†åˆ†ï¼š{matches}")
        for å­—, è¨»1, è¨»2 in matches:
            è¨» = è¨»1 or è¨»2 or ""
            print(f"ğŸ§© å­—ï¼š{å­—}ï¼ŒéŸ³ï¼š{phon}ï¼Œè¨»ï¼š{è¨»}")
            result.append((å­—, phon, è¨»))
        return result

    for i, row in enumerate(sheet.iter_rows(values_only=True), start=1):
        if not row or str(row[0]).startswith("#"):
            continue
        parsed = parse_row(row, i)
        for å­—, éŸ³, è¨» in parsed:
            clean_str, mapping = s2t_pro(å­—, level)
            mapping = dict(mapping)
            candidates = mapping.get(å­—, [å­—])  # æ”¯æ´å¤šå€™é¸

            for cand in candidates:
                rows.append([cand, éŸ³, è¨»])
                if cand != å­—:
                    simplified_rows.append([cand, éŸ³, è¨», "ç°¡"])
                    print(f"ğŸ” å­—å½¢è½‰æ›ï¼š{å­—} â†’ {cand}")

    outpath = output_path or os.path.splitext(file)[0] + ".tsv"
    with open(outpath, "w", encoding="utf-8", newline="\n") as out:
        writer = csv.writer(out, delimiter="\t")
        writer.writerow(["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹"])
        writer.writerows(rows)
    print(f"âœ… ä¸»æª”è¼¸å‡ºå®Œæˆï¼š{outpath}")

    simp_path = os.path.splitext(file)[0] + ".ç°¡.tsv"
    if simplified_rows:
        with open(simp_path, "w", encoding="utf-8", newline="\n") as out:
            writer = csv.writer(out, delimiter="\t")
            writer.writerow(["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹", "ç¹ç°¡"])
            writer.writerows(simplified_rows)
        print(f"[ç°¡é«”] å…±ç™¼ç¾ {len(simplified_rows)} ç­†ç°¡é«”è©å½™ï¼Œå¯«å…¥ï¼š{simp_path}")

    print(f"ğŸ‰ å…¨éƒ¨è™•ç†å®Œæˆï¼Œå…± {len(rows)} æ¢è¨˜éŒ„")
    # print(f"âœ… è¼¸å‡ºï¼š{outpath}")


# ========== ç¸£å¿—æ ¼å¼è™•ç† ==========
def process_ç¸£å¿—_excel(file, level=1, output_path=None):
    # cc = OpenCC('s2t')
    rows = []
    simplified_rows = []
    debug = True

    # def s2t(text, level=1):
    #     return cc.convert(text)

    def process_lines(è¡Œ):
        è¡Œ = è¡Œ.strip()
        if not è¡Œ:
            return None
        if è¡Œ.startswith("#"):
            return è¡Œ
        è¡Œ = re.sub(r":\[", "\t[", è¡Œ)
        è¡Œ = è¡Œ.replace("(", "{").replace(")", "}")
        è¡Œ = re.sub(r"\[(\d+)\]", r"ï¼»\1ï¼½", è¡Œ)
        è¡Œ = re.sub(r"ï¼»([^\d]+.*?)ï¼½", r"[\1]", è¡Œ)
        return è¡Œ

    ext = os.path.splitext(file)[1].lower()
    if ext in [".xlsx", ".xls"]:
        df = pd.read_excel(file, sheet_name=0, header=None)
        lines = [
            "\t".join([str(cell) for cell in row if pd.notna(cell)]).strip()
            for _, row in df.iterrows()
        ]
        print(f"ğŸ“– è®€å– Excelï¼š{file}")
    else:
        encodings = ["utf-8", "utf-8-sig", "big5", "gb18030"]
        for enc in encodings:
            try:
                with open(file, encoding=enc) as f:
                    lines = f.readlines()
                print(f"ğŸ“– ä½¿ç”¨ç·¨ç¢¼ï¼š{enc}")
                break
            except UnicodeDecodeError:
                continue
        else:
            raise UnicodeDecodeError("âŒ ç„¡æ³•è®€å–æ–‡ä»¶ï¼Œè«‹ç¢ºèªç·¨ç¢¼æ ¼å¼")

    total, skipped, simplified_count = 0, 0, 0

    for lineno, line in enumerate(lines, 1):
        total += 1
        raw_line = line
        line = process_lines(line)
        if line is None:
            skipped += 1
            continue

        if line.startswith("#æ¼¢å­—"):
            skipped += 1
            continue
        if line.startswith("#"):
            continue

        parts = line.split("\t")
        if len(parts) < 2:
            if debug:
                print(f"âš ï¸ è·³éè¡Œ {lineno}ï¼ˆåˆ†æ¬„ä¸è¶³ï¼‰: {raw_line.strip()}")
            skipped += 1
            continue

        æ‹¼éŸ³ = parts[0].strip()
        for cell in parts[1:]:
            matches = re.findall(r"[ï¼»\[](\d+[a-z]?)[ï¼½\]](.+?)(?=([ï¼»\[]\d|$))", cell)
            if not matches:
                if debug:
                    print(f"âš ï¸ ç„¡éŸ³ç¯€åŒ¹é… è¡Œ {lineno}: {cell}")
                continue

            for èª¿è™Ÿ, ç¾©é …, _ in matches:
                if debug:
                    print(f"ğŸ” è¡Œ {lineno}ï¼šæ‹¼éŸ³={æ‹¼éŸ³}, èª¿è™Ÿ={èª¿è™Ÿ}, ç¾©é …={ç¾©é …}")

                # é€å­—æƒæç¾©é …ï¼Œè‹¥æŸå­—å¾Œç·Šè·Ÿè¨»é‡‹ï¼Œå°±ç¶å®šåœ¨é‚£å€‹å­—ä¸Š
                i = 0
                while i < len(ç¾©é …):
                    å­— = ç¾©é …[i]
                    è¨» = ""
                    if i + 1 < len(ç¾©é …) and ç¾©é …[i + 1] in "{ï½›":
                        m = re.match(r"[{ï½›]([^{}ï½›ï½]+)[}ï½]", ç¾©é …[i + 1:])
                        if m:
                            è¨» = m.group(1)
                            i += len(m.group(0))  # è·³éæ•´å€‹ {è¨»é‡‹}
                    i += 1
                    å­— = å­—.strip()
                    if not å­—:
                        if debug:
                            print(f"âš ï¸ ç©ºç™½å­— è¡Œ {lineno} ç¾©é …ï¼š{ç¾©é …}")
                        continue
                    clean_str, mapping = s2t_pro(å­—, level)
                    mapping = dict(mapping)
                    candidates = mapping.get(å­—, [å­—])  # æ”¯æ´å¤šå€™é¸ç¹é«”å­—

                    éŸ³æ¨™ = f"{æ‹¼éŸ³}{èª¿è™Ÿ}"
                    for cand in candidates:
                        row = [cand, éŸ³æ¨™, è¨»]
                        rows.append(row)
                        if cand != å­—:
                            simplified_rows.append(row + ["ç°¡"])
                            simplified_count += 1
                            if debug:
                                print(f"ğŸ” å­—å½¢è½‰æ›ï¼š{å­—} â†’ {cand}")

    outpath = output_path or os.path.splitext(file)[0] + ".tsv"
    with open(outpath, "w", encoding="utf-8", newline="\n") as out:
        writer = csv.writer(out, delimiter="\t")
        writer.writerow(["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹"])
        writer.writerows(rows)
    print(f"âœ… ä¸»æª”è¼¸å‡ºå®Œæˆï¼š{outpath}")

    simp_path = os.path.splitext(file)[0] + ".ç°¡.tsv"
    if simplified_rows:
        with open(simp_path, "w", encoding="utf-8", newline="\n") as out:
            writer = csv.writer(out, delimiter="\t")
            writer.writerow(["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹", "ç¹ç°¡"])
            writer.writerows(simplified_rows)
        print(f"[ç°¡é«”] å…±ç™¼ç¾ {len(simplified_rows)} ç­†ç°¡é«”è©å½™ï¼Œå¯«å…¥ï¼š{simp_path}")

    print(f"ğŸ“Š è¡Œæ•¸çµ±è¨ˆï¼šç¸½è¡Œæ•¸ {total}, è·³é {skipped} è¡Œ, æ¨™è¨»ç°¡é«” {simplified_count} æ¢")


def process_ç¸£å¿—_word(file, level=1, output_path=None):
    print(f"ğŸ“– è®€å– wordï¼š{file}")
    tsv_path = convert_to_tsv_if_needed(file)
    with open(tsv_path, encoding="utf-8") as f:
        raw = f.read()

    def parse_entry_blocks(text):
        results = []

        current_vowel = None  # e.g., 'i', 'u'

        for line in text.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("#"):
                current_vowel = line[1:]
                continue

            match = re.match(r"^([^\[]+)", line)
            if not match or not current_vowel:
                continue

            initial = match.group(1).strip()
            segments = re.findall(r"\[(\d+)]([^\[]+)", line)

            for tone, content in segments:
                syllable = f"{initial}{current_vowel}{tone}"
                chars = []
                explanations = {}
                temp = ""
                in_brace = False
                current_char = ""

                for c in content:
                    if c == "{":
                        in_brace = True
                        temp = ""
                    elif c == "}":
                        in_brace = False
                        explanations[current_char] = temp
                        temp = ""
                    elif in_brace:
                        temp += c
                    else:
                        current_char = c
                        chars.append(c)

                for char in chars:
                    explanation = explanations.get(char, "")
                    results.append((char, syllable, explanation))

        return results
    data = parse_entry_blocks(raw)
    outpath = output_path or os.path.splitext(file)[0] + ".tsv"
    df = pd.DataFrame(data, columns=["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹"])
    df.to_csv(outpath, sep="\t", index=False)
    # print(f"[âœ…] è½‰æ›å®Œæˆï¼Œè¼¸å‡ºè·¯å¾‘ï¼š{outpath}")

    with open(outpath, encoding="utf-8") as f:
        lines = [line.rstrip("\n").split("\t") for line in f if line.strip() and not line.startswith("#")]
        # print("lines:",lines)

    index = {'æ¼¢å­—': 0, 'éŸ³æ¨™': 1, 'è§£é‡‹': 2}
    print(f"[è™•ç†] é–‹å§‹æƒæè³‡æ–™è¡Œï¼Œå…± {len(lines) - 1} ç­†")

    delimiters = [';', 'ï¼›', '/', 'ã€', ',', 'ï¼Œ']

    rows = []
    simplified_rows = []

    def split_field(field):
        for delim in delimiters:
            field = field.replace(delim, 'âˆ¥')
        return [f.strip() for f in field.split('âˆ¥') if f.strip()]

    def get_field(parts, field_name):
        idx = index.get(field_name)
        if idx is not None and idx < len(parts):
            return parts[idx].strip()
        return ""

    def process_pair(word, phon, note, row_num):
        clean_str, mapping = s2t_pro(word, level)
        mapping = dict(mapping)
        phon_units = phon.strip().split()
        word_len_match = len(word) == len(phon_units)

        if word_len_match:
            for ch, p in zip(word, phon_units):
                candidates = mapping.get(ch, [ch])
                for cand in candidates:
                    rows.append([cand, p, note])
                    if cand != ch:
                        simplified_rows.append([cand, p, note, "ç°¡"])
                        print(f"[ç°¡é«”ä¸€å°å¤š] ç¬¬ {row_num} è¡Œï¼š{ch} â†’ {cand}")
        else:
            rows.append([clean_str, phon, note])
            if clean_str != word:
                simplified_rows.append([clean_str, phon, note, "ç°¡"])
                print(f"[fallback] ç¬¬ {row_num} è¡Œï¼š{word} â†’ {clean_str}")

    print(f"[è™•ç†] é–‹å§‹æƒæè³‡æ–™è¡Œï¼Œå…± {len(lines) - 1} ç­†")

    for row_num, parts in enumerate(lines[1:], start=2):
        word_raw = get_field(parts, 'æ¼¢å­—')
        phon_raw = get_field(parts, 'éŸ³æ¨™')
        note = get_field(parts, 'è§£é‡‹')

        if not word_raw or not phon_raw:
            continue

        word_list = split_field(word_raw)
        phon_list = split_field(phon_raw)

        if not word_list or not phon_list:
            print(f"âš ï¸ è·³éç¬¬ {row_num} è¡Œï¼Œå› ç‚ºæ¼¢å­—æˆ–éŸ³æ¨™æ¸…å–®ç‚ºç©º")
            continue

        if len(word_list) > 1 and len(phon_list) > 1:
            print(f"[ç¬›å¡çˆ¾ç©] ç¬¬ {row_num} è¡Œï¼š{word_list} Ã— {phon_list}")
            for word, phon in product(word_list, phon_list):
                process_pair(word, phon, note, row_num)

        elif len(word_list) > 1 and len(phon_list) == 1:
            print(f"[å¤šå°ä¸€] ç¬¬ {row_num} è¡Œï¼š{word_list} Ã— {phon_list[0]}")
            for word in word_list:
                process_pair(word, phon_list[0], note, row_num)

        elif len(word_list) == 1 and len(phon_list) > 1:
            print(f"[ä¸€å°å¤š] ç¬¬ {row_num} è¡Œï¼š{word_list[0]} Ã— {phon_list}")
            for phon in phon_list:
                process_pair(word_list[0], phon, note, row_num)

        else:
            word = ''.join(word_list)
            phon = ' '.join(phon_list)
            # print(f"[fallback] ç¬¬ {row_num} è¡Œï¼š{word} â†’ {phon}")
            process_pair(word, phon, note, row_num)

    # Step 5: è¼¸å‡ºæœ€çµ‚ TSV
    # final_outpath = output_path or (os.path.splitext(file)[0] + ".tsv")
    with open(outpath, "w", encoding="utf-8", newline="\n") as out:
        writer = csv.writer(out, delimiter="\t")
        writer.writerow(["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹"])
        writer.writerows(rows)

    # Step 6: è¼¸å‡ºç°¡é«”è³‡æ–™
    simp_path = os.path.splitext(file)[0] + ".ç°¡.tsv"
    if simplified_rows:
        print(f"[ç°¡é«”] å…±ç™¼ç¾ {len(simplified_rows)} ç­†ç°¡é«”è©å½™ï¼Œå¯«å…¥ï¼š{simp_path}")
        with open(simp_path, "w", encoding="utf-8", newline="\n") as out:
            writer = csv.writer(out, delimiter="\t")
            writer.writerow(["#æ¼¢å­—", "éŸ³æ¨™", "è§£é‡‹", "ç¹ç°¡"])
            writer.writerows(simplified_rows)

    print(f"âœ… å…¨éƒ¨è™•ç†å®Œæˆï¼š{outpath}")


def process_ç¸£å¿—(file, level=1, output_path=None):
    ext = os.path.splitext(file)[1].lower()
    if ext in [".xlsx", ".xls"]:
        process_ç¸£å¿—_excel(file, level, output_path)
    elif ext in [".docx", ".doc"]:
        process_ç¸£å¿—_word(file, level, output_path)


# if __name__ == "__main__":
#     # âœ… tkinter æª”æ¡ˆé¸æ“‡å™¨
#     Tk().withdraw()  # ä¸é¡¯ç¤ºä¸»è¦–çª—
#     file_path = filedialog.askopenfilename(
#         title="é¸æ“‡ç¸£å¿—æª”æ¡ˆ",
#         filetypes=[("word Files", "*.docx"),("excel files", "*.xlsx"), ("All Files", "*.*")]
#     )
#
#     if file_path:
#         # convert_to_tsv_if_needed(file_path)
#         process_ç¸£å¿—_word(file_path)
#     else:
#         print("âŒ æ²’æœ‰é¸æ“‡ä»»ä½•æª”æ¡ˆ")
