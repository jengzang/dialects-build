import re
import sqlite3

import pandas as pd

from common.config import CHARACTERS_DB_PATH, DIALECTS_DB_PATH
from common.constants import HIERARCHY_COLUMNS, AMBIG_VALUES
from scripts.check.process_sp_input import auto_convert_batch
from common.getloc_by_name_region import query_dialect_abbreviations
from scripts.check.match_input_tip import match_locations_batch

"""
æœ¬è…³æœ¬æä¾›ä¸€çµ„å‡½æ•¸ç”¨æ–¼å¾èªéŸ³æè¿°è©æŸ¥è©¢å°æ‡‰æ¼¢å­—ï¼Œä¸¦æ ¹æ“šä¸åŒåœ°é»èˆ‡èªéŸ³ç‰¹å¾µé€²è¡Œçµ±è¨ˆåˆ†æã€‚
æ ¸å¿ƒæµç¨‹èˆ‡åŠŸèƒ½å¦‚ä¸‹ï¼š

1. run_statusï¼š
   â¤ å°‡ä½¿ç”¨è€…è¼¸å…¥ï¼ˆå¦‚ã€ŒçŸ¥çµ„ä¸‰ã€ï¼‰è§£æç‚ºç¯©é¸èªæ³•ä¸¦æŸ¥è©¢ characters.dbï¼Œå›å‚³æ¼¢å­—èˆ‡å¤šåœ°ä½å­—ã€‚

2. query_characters_by_pathï¼š
   â¤ è§£æ [å€¼]{æ¬„ä½} èªæ³•ï¼ŒåŸ·è¡Œè³‡æ–™åº«æŸ¥è©¢ä¸¦åˆ¤å®šå¤šåœ°ä½ã€‚

3. query_by_statusï¼š
   â¤ æ ¹æ“šæŸ¥å¾—æ¼¢å­—ï¼Œåœ¨æŒ‡å®šåœ°é»èˆ‡èªéŸ³ç‰¹å¾µä¸‹è¨ˆç®—çµ±è¨ˆè³‡è¨Šèˆ‡å¤šéŸ³å­—è©³æƒ…ã€‚

4. run_feature_analysisï¼š
   â¤ æ•´åˆ run_status èˆ‡ query_by_statusï¼Œæ‰¹æ¬¡è™•ç†å¤šçµ„è¼¸å…¥èˆ‡åœ°é»ï¼Œé€²è¡Œå®Œæ•´åˆ†ææµç¨‹ã€‚

"""


def query_characters_by_path(path_string, db_path=CHARACTERS_DB_PATH, table="characters"):
    """
    ğŸ“Œ æ ¹æ“šç”¨æˆ¶è¼¸å…¥èªæ³•ï¼ˆå¦‚ "[çŸ¥]{çµ„}[ä¸‰]{ç­‰}"ï¼‰å¾ characters.db ä¸­æŸ¥å‡ºç¬¦åˆæ¢ä»¶çš„æ¼¢å­—ã€‚

    åŠŸèƒ½åŒ…å«ï¼š
    - è§£æèªæ³•ä¸­æŒ‡å®šçš„ã€Œæ¬„ä½ + å€¼ã€æ¢ä»¶
    - æ ¹æ“šæ¢ä»¶ç¯©é¸å‡ºç¬¦åˆçš„æ¼¢å­—
    - é¡å¤–åˆ†æé€™äº›å­—æ˜¯å¦ç‚ºã€Œå¤šåœ°ä½ã€å­—ï¼ˆå³ä¸€å­—å¤šå€‹éŸ³ç³»åœ°ä½ï¼‰

    å›å‚³ï¼š
    - ç¬¦åˆæ¢ä»¶çš„æ¼¢å­—æ¸…å–®
    - å¤šåœ°ä½çš„æ¼¢å­—æ¸…å–®
    """

    # print(f"\nğŸ“¥ æŸ¥è©¢èªæ³•è¼¸å…¥ï¼š{path_string}")

    # è§£æèªæ³•ï¼š[å€¼]{æ¬„ä½}
    pattern = r"\[([^\[\]]+)\]\{([^\{\}]+)\}"
    matches = re.findall(pattern, path_string)

    if not matches:
        print("âŒ ç„¡æ³•è§£æè¼¸å…¥èªæ³•ã€‚è«‹ä½¿ç”¨ [å€¼]{æ¬„ä½} çš„æ ¼å¼")
        return [], []

    # print(f"ğŸ” è§£æå‡ºçš„æ¢ä»¶ï¼š{matches}")

    filter_columns = [col for _, col in matches]
    for col in filter_columns:
        if col not in HIERARCHY_COLUMNS:
            print(f"âš ï¸ æ¬„ä½ã€Œ{col}ã€ä¸åœ¨å…è¨±çš„å±¤ç´šæ¬„ä½ä¸­")
            return [], []

    # è®€å–è³‡æ–™
    conn = sqlite3.connect(db_path)
    # df = pd.read_sql_query(f"SELECT * FROM {table}", conn)
    # å‹•æ…‹çµ„è£ WHERE å­å¥ï¼ˆæ ¹æ“š matchesï¼‰
    where_clause = " AND ".join([f"{col} = ?" for _, col in matches])
    values = [val for val, _ in matches]

    query = f"SELECT * FROM {table} WHERE {where_clause}"
    df = pd.read_sql_query(query, conn, params=values)

    conn.close()

    # åŸ·è¡Œç¯©é¸
    filtered_df = df.copy()
    for value, column in matches:
        before = len(filtered_df)
        filtered_df = filtered_df[filtered_df[column] == value]
        after = len(filtered_df)
        print(f"ğŸ”½ ç¯©é¸ {column} = {value}ï¼šå‰©ä¸‹ {after} ç­†ï¼ˆåŸæœ¬ {before} ç­†ï¼‰")
        if after == 0:
            # raise HTTPException(status_code=404, detail="âŒ è¼¸å…¥çš„ä¸­å¤åœ°ä½ä¸å­˜åœ¨")
            return [], []

    # æå–æ¼¢å­—
    if "æ¼¢å­—" not in filtered_df.columns:
        print("âŒ ç¼ºå°‘ã€Œæ¼¢å­—ã€æ¬„")
        return [], []

    characters = filtered_df["æ¼¢å­—"].dropna().tolist()
    # print(f"\nğŸ¯ ç¬¦åˆæ¢ä»¶çš„æ¼¢å­—å…± {len(characters)} å€‹")

    # å¤šåœ°ä½éæ¿¾ï¼ˆå„ªåŒ–åˆ¤æ–·ï¼‰
    multi_chars = []
    if "å¤šåœ°ä½æ¨™è¨˜" in filtered_df.columns:
        candidates = filtered_df[
            filtered_df["å¤šåœ°ä½æ¨™è¨˜"] == "1"
            ]["æ¼¢å­—"].dropna().unique().tolist()

        # print(f"ğŸŸ¡ åˆæ­¥å¤šåœ°ä½æ¨™è¨˜å€™é¸ï¼š{len(candidates)} å­—")

        for word in candidates:
            all_rows = df[df["æ¼¢å­—"] == word]
            sub = all_rows[filter_columns].drop_duplicates()
            if len(sub) > 1:
                multi_chars.append(word)

        # print(f"ğŸŸ  ç¶“éæ¯”å°å¾Œç¢ºå®šæœ‰å¤šåœ°ä½çš„æ¼¢å­—ï¼š{len(multi_chars)} å­—")
    else:
        print("âš ï¸ ç„¡ã€Œå¤šåœ°ä½æ¨™è¨˜ã€æ¬„")

    return characters, multi_chars


def query_by_status(char_list, locations, features, user_input, db_path=DIALECTS_DB_PATH, table="dialects"):
    """
    ğŸ“Œ æ ¹æ“šæä¾›çš„æ¼¢å­—åå–®ï¼ŒæŸ¥è©¢å…¶åœ¨ä¸åŒåœ°é»èˆ‡èªéŸ³ç‰¹å¾µï¼ˆå¦‚è²æ¯/éŸ»æ¯ï¼‰ä¸‹çš„åˆ†ä½ˆæƒ…æ³ã€‚

    åŠŸèƒ½åŒ…å«ï¼š
    - å¾ dialects.db ä¸­æ‰¾å‡ºæŒ‡å®šåœ°é»èˆ‡æ¼¢å­—çš„è³‡æ–™
    - è¨ˆç®—æ¯ç¨®èªéŸ³ç‰¹å¾µå€¼ï¼ˆå¦‚ b, p, m...ï¼‰çš„å­—æ•¸ã€æ¯”ä¾‹ï¼ˆå»é‡å¾Œï¼‰
    - è™•ç†ã€Œå¤šéŸ³å­—ã€çš„è©³ç´°éŸ³ç¯€è³‡è¨Šï¼ˆä¿ç•™æ‰€æœ‰å°æ‡‰çš„ç™¼éŸ³ï¼‰
    - è¼¸å‡ºæ¬„ä½åŒ…å«ï¼šåˆ†çµ„å€¼ï¼ˆç‰¹å¾µ=å€¼ï¼‰

    å›å‚³ï¼š
    - æ¯ç­†çµ±è¨ˆçµæœä»¥å­—å…¸æ–¹å¼è¼¸å‡ºï¼Œæœ€çµ‚è½‰ç‚º DataFrame
    """
    # print(f"ğŸ“¦ é€£æ¥è³‡æ–™åº«ï¼š{db_path}")
    conn = sqlite3.connect(db_path)

    # 1. åªé¸æ“‡éœ€è¦çš„æ¬„ä½ä¸¦æ·»åŠ éæ¿¾æ¢ä»¶ï¼Œæ¸›å°‘è³‡æ–™åº«åŠ è¼‰é‡
    query = f"""
    SELECT ç°¡ç¨±, æ¼¢å­—, {', '.join(features)}, å¤šéŸ³å­—, éŸ³ç¯€
    FROM {table}
    WHERE ç°¡ç¨± IN ({','.join(f"'{loc}'" for loc in locations)}) 
    AND æ¼¢å­— IN ({','.join(f"'{char}'" for char in char_list)})
    """
    try:
        df = pd.read_sql_query(query, conn)
        print(f"âœ… æŸ¥è©¢çµæœï¼šè¼‰å…¥ {len(df)} æ¢è³‡æ–™")
    except Exception as e:
        print(f"âŒ æŸ¥è©¢å¤±æ•—ï¼š{e}")
    conn.close()

    # 2. ç‚ºæ¯å€‹åœ°é»åˆ†åˆ¥æŸ¥è©¢å¤šéŸ³å­—è³‡æ–™ï¼Œä¸¦æ§‹å»ºå¤šéŸ³å­—å­—å…¸
    poly_dicts = {}  # å­˜å„²æ¯å€‹åœ°é»çš„å¤šéŸ³å­—å­—å…¸
    for loc in locations:
        # é‡å°æ¯å€‹åœ°é»é€²è¡ŒæŸ¥è©¢
        # print(f"ğŸ” æŸ¥è©¢åœ°é»ï¼š{loc}")
        conn = sqlite3.connect(db_path)
        try:
            # æŸ¥è©¢è©²åœ°é»çš„å¤šéŸ³å­—è³‡æ–™
            query = f"""
            SELECT æ¼¢å­—, éŸ³ç¯€ 
            FROM {table} 
            WHERE å¤šéŸ³å­— = '1' 
            AND ç°¡ç¨± = '{loc}' 
            AND æ¼¢å­— IN ({','.join(f"'{char}'" for char in char_list)})
            """
            poly_data = pd.read_sql_query(query, conn)
            # print(f"âœ… åœ°é» {loc} çš„å¤šéŸ³å­—è³‡æ–™è¼‰å…¥å®Œæˆï¼Œå…± {len(poly_data)} æ¢")
        except Exception as e:
            print(f"âŒ æŸ¥è©¢åœ°é» {loc} çš„å¤šéŸ³å­—è³‡æ–™å¤±æ•—ï¼š{e}")
        conn.close()

        # æ§‹å»ºè©²åœ°é»çš„å¤šéŸ³å­—å­—å…¸
        poly_dict = poly_data.groupby("æ¼¢å­—")["éŸ³ç¯€"].apply(lambda x: '|'.join(x)).to_dict()
        poly_dicts[loc] = poly_dict
        print(f"âœ… åœ°é» {loc} çš„å¤šéŸ³å­—å­—å…¸å»ºæ§‹å®Œæˆï¼Œå…± {len(poly_dict)} æ¢")

    # 3. é–‹å§‹è™•ç†è³‡æ–™
    results = []

    # print("ğŸ” é–‹å§‹è™•ç†åœ°é»å’Œç‰¹å¾µ...")

    for loc in locations:
        # print(f"\nğŸ” è™•ç†åœ°é»ï¼š{loc}")
        loc_df = df[df["ç°¡ç¨±"] == loc]
        # print(f"   - è©²åœ°è³‡æ–™ç­†æ•¸ï¼š{len(loc_df)}")

        loc_chars_df = loc_df[loc_df["æ¼¢å­—"].isin(char_list)]
        # print(f"   - åŒ¹é…è¼¸å…¥æ¼¢å­—ç­†æ•¸ï¼š{len(loc_chars_df)} / {len(char_list)}")

        if loc_chars_df.empty:
            print("   âš ï¸ ç„¡ç¬¦åˆæ¼¢å­—ï¼Œç•¥éæ­¤åœ°é»")
            results.append({
                "åœ°é»": loc,
                "ç‰¹å¾µé¡åˆ¥": "ç„¡",
                "ç‰¹å¾µå€¼": "ç„¡",
                "åˆ†çµ„å€¼": {},
                "å­—æ•¸": 0,
                "ä½”æ¯”": 0.0,
                "å°æ‡‰å­—": [],
                "å¤šéŸ³å­—è©³æƒ…": "âŒ ç„¡ç¬¦åˆæ¼¢å­—"
            })
            continue

        total_chars = len(loc_chars_df["æ¼¢å­—"].unique())
        # print(f"   - ç¸½å…±å­—æ•¸ï¼š{total_chars}")

        for feature in features:
            # print(f"   ğŸ” è™•ç†ç‰¹å¾µï¼š{feature}")
            feature_groups = loc_chars_df.groupby(feature)

            for fval, sub_df in feature_groups:
                all_chars = sub_df["æ¼¢å­—"].tolist()
                unique_chars = list(set(all_chars))
                count = len(unique_chars)

                # print(f"     â–¶ï¸ {feature} = {fval}ï¼Œå­—æ•¸ï¼š{count}ï¼Œå­—ä¾‹ï¼š{unique_chars[:5]}...")

                poly_details = []
                # ä½¿ç”¨è©²åœ°é»çš„å¤šéŸ³å­—å­—å…¸
                poly_dict = poly_dicts.get(loc, {})
                for hz in unique_chars:
                    if hz in poly_dict:
                        poly_details.append(f"{hz}:{poly_dict[hz]}")

                results.append({
                    "åœ°é»": loc,
                    "ç‰¹å¾µé¡åˆ¥": feature,
                    "ç‰¹å¾µå€¼": user_input,
                    "åˆ†çµ„å€¼": {user_input: fval},
                    "å­—æ•¸": count,
                    "ä½”æ¯”": round(count / total_chars, 4) if total_chars else 0.0,
                    "å°æ‡‰å­—": unique_chars,
                    "å¤šéŸ³å­—è©³æƒ…": "; ".join(poly_details) if poly_details else ""
                })

    # print("\nâœ… åˆ†æå®Œæˆï¼")

    # è¿”å›çµæœ
    return pd.DataFrame(results)


def run_status(
        input_strings,
        db_path=CHARACTERS_DB_PATH,
        table="characters",
):
    """
           ğŸ“Œ åŠŸèƒ½ç¸½çµï¼š

       ğŸ”¹ ä¸»è¦ç”¨é€”ï¼š
       æ¥æ”¶ä¸€çµ„èªéŸ³æ¢ä»¶è¼¸å…¥å­—ä¸²ï¼ˆå¦‚ã€ŒçŸ¥çµ„ä¸‰ã€ã€ã€ŒèŸ¹æ”ã€ï¼‰ï¼Œ
       å°‡å…¶è½‰æ›ç‚ºä¸€å€‹æˆ–å¤šå€‹æ¨™æº–æŸ¥è©¢èªæ³•ï¼ˆpathï¼‰ï¼Œä¸¦æŸ¥è©¢ç¬¦åˆæ¢ä»¶çš„æ¼¢å­—ã€‚

       ğŸ” æ¯å€‹æ¢ä»¶è¼¸å…¥å¯èƒ½æœƒå°æ‡‰åˆ°å¤šå€‹ pathï¼ˆå¦‚ç­‰ç´šã€çµ„ã€æ”çš„å±•é–‹ï¼‰ï¼Œ
       æœ¬å‡½æ•¸æœƒå°æ¯å€‹ path ç¨ç«‹æŸ¥è©¢ï¼Œå†å°‡çµæœåˆä½µè¿”å›ã€‚

       âœ” è™•ç†æµç¨‹ï¼š
       1. èª¿ç”¨ `auto_convert_batch(s)` å°‡æ¯å€‹è¼¸å…¥è½‰æ›ç‚ºå¤šå€‹ pathï¼ˆå¦‚ [çŸ¥]{çµ„}-[ä¸‰]{ç­‰}ï¼‰
       2. æ¯å€‹ path ç”¨ `query_characters_by_path()` æŸ¥å‡ºç¬¦åˆçš„æ¼¢å­—èˆ‡å¤šåœ°ä½å­—
       3. æœ€å¾Œå°‡æ¯å€‹è¼¸å…¥çš„æ‰€æœ‰ path æŸ¥å¾—çš„å­—èˆ‡å¤šåœ°ä½å­—åˆä½µ
       4. å›å‚³æ ¼å¼ä¿ç•™èˆ‡èˆŠç‰ˆæœ¬ä¸€è‡´ï¼Œä»¥æ”¯æ´åŸå…ˆ `sta2pho` ç”¨æ³•

       ğŸ§¾ å›å‚³å…§å®¹ï¼š
       - Listï¼Œæ¯å€‹å…ƒç´ ç‚ºä¸€å€‹ tupleï¼š
           (
               åŸå§‹è¼¸å…¥å­—ä¸²,           # ä¾‹å¦‚ "èŸ¹æ”"
               åˆä½µå¾Œçš„æ¼¢å­—æ¸…å–®,       # e.g., ["å”", "äº›", "æ–œ"]
               åˆä½µå¾Œçš„å¤šåœ°ä½å­—æ¸…å–®,   # e.g., ["å”"]
               æ¯å€‹ path çš„æ˜ç´°æ¸…å–®     # list of dictsï¼ˆå« pathã€charactersã€multiï¼‰
           )
    """
    results_summary = []

    def convert_path_str(path_str: str) -> str:
        """
        å°‡æ ¼å¼ [èŠ]{çµ„}[å®•]{æ”} è½‰æ›ç‚ºï¼š
        - è‹¥å€¼åœ¨ AMBIG_VALUES ä¸­ï¼ˆæœ‰æ­§ç¾©ï¼‰ï¼Œä¿ç•™ {æ¬„ä½} â†’ èŠçµ„
        - å¦å‰‡åªä¿ç•™å€¼ â†’ å®•
        æœ€çµ‚ä»¥ - ä¸²æ¥
        """
        items = re.findall(r'[\[\{](.*?)[\]\}]', path_str)
        pairs = []
        for i in range(0, len(items), 2):
            val, col = items[i], items[i + 1]
            if val in AMBIG_VALUES:
                pairs.append(val + col)
            else:
                pairs.append(val)
        return 'Â·'.join(pairs)

    for s in input_strings:
        if "-" in s:
            # â¤ ä¿ç•™åŸé‚è¼¯ï¼šå«æœ‰ç ´æŠ˜è™Ÿï¼Œç›´æ¥è™•ç†æ•´é«”
            batch_result = auto_convert_batch(s)

            if not isinstance(batch_result, list):
                results_summary.append((s, False, False))
                print(f"  âŒ ç„¡æ³•è™•ç†ï¼ˆé list çµæœï¼‰ï¼š{s}")
                continue

            has_error = any(
                isinstance(r, tuple) and r[0] is False for r in batch_result
            )

            path_results = []

            for path_tuple in batch_result:
                if isinstance(path_tuple, tuple) and path_tuple[0] is not False:
                    path_str = path_tuple[0]
                    characters, multi_chars = query_characters_by_path(
                        path_str, db_path=db_path, table=table
                    )
                    # simplified_input = ''.join(re.findall(r'\[(.*?)\]', path_str))
                    simplified_input = convert_path_str(path_str)
                    # print(f"path_str0{path_str}")
                    # print(f"simpilfied0_input{simplified_input}")
                    path_results.append({
                        "path": simplified_input,
                        "characters": characters,
                        "multi": multi_chars
                    })

            if path_results:
                all_chars = []
                all_multi = []
                for result in path_results:
                    all_chars.extend(result["characters"])
                    all_multi.extend(result["multi"])
                results_summary.append((s, all_chars, list(set(all_multi)), path_results))
            else:
                results_summary.append((s, False, False, []))

            if has_error:
                print(f"  âš ï¸ éƒ¨åˆ†ç‰‡æ®µè½‰æ›å¤±æ•—ï¼š{s}")

        elif " " in s:
            # â¤ ä¸å«ç ´æŠ˜è™Ÿä½†æœ‰ç©ºæ ¼ï¼šå¤šæ®µåˆä½µè™•ç†
            parts = s.split()
            all_chars = []
            all_multi = []
            has_error = False

            for part in parts:
                batch_result = auto_convert_batch(part)

                if not isinstance(batch_result, list):
                    has_error = True
                    continue

                if any(isinstance(r, tuple) and r[0] is False for r in batch_result):
                    has_error = True

                for path_tuple in batch_result:
                    if isinstance(path_tuple, tuple) and path_tuple[0] is not False:
                        path_str = path_tuple[0]
                        characters, multi_chars = query_characters_by_path(
                            path_str, db_path=db_path, table=table
                        )
                        all_chars.extend(characters)
                        all_multi.extend(multi_chars)
            # print(f"s{s}")
            if all_chars:
                results_summary.append((
                    s,
                    all_chars,
                    list(set(all_multi)),
                    [{
                        "path": s,
                        "characters": all_chars,
                        "multi": list(set(all_multi))
                    }]
                ))
            else:
                results_summary.append((s, False, False, []))

            if has_error:
                print(f"  âš ï¸ éƒ¨åˆ†ç‰‡æ®µè½‰æ›å¤±æ•—ï¼š{s}")

        else:
            # â¤ å–®æ®µè™•ç†ï¼ˆç„¡ç ´æŠ˜è™Ÿã€ç„¡ç©ºæ ¼ï¼‰
            batch_result = auto_convert_batch(s)

            if not isinstance(batch_result, list):
                results_summary.append((s, False, False))
                print(f"  âŒ ç„¡æ³•è™•ç†ï¼ˆé list çµæœï¼‰ï¼š{s}")
                continue

            has_error = any(
                isinstance(r, tuple) and r[0] is False for r in batch_result
            )

            path_results = []

            for path_tuple in batch_result:
                if isinstance(path_tuple, tuple) and path_tuple[0] is not False:
                    path_str = path_tuple[0]
                    characters, multi_chars = query_characters_by_path(
                        path_str, db_path=db_path, table=table
                    )
                    # simplified_input = ''.join(re.findall(r'\[(.*?)\]', path_str))
                    simplified_input = convert_path_str(path_str)
                    # print(f"path_str{path_str}")
                    # print(f"simpilfied_input{simplified_input}")
                    path_results.append({
                        "path": simplified_input,
                        "characters": characters,
                        "multi": multi_chars
                    })

            if path_results:
                all_chars = []
                all_multi = []
                for result in path_results:
                    all_chars.extend(result["characters"])
                    all_multi.extend(result["multi"])
                results_summary.append((s, all_chars, list(set(all_multi)), path_results))
            else:
                results_summary.append((s, False, False, []))

            if has_error:
                print(f"  âš ï¸ éƒ¨åˆ†ç‰‡æ®µè½‰æ›å¤±æ•—ï¼š{s}")

    return results_summary


def sta2pho(
        locations,
        regions,
        features,
        test_inputs,
        db_path_char=CHARACTERS_DB_PATH,
        db_path_dialect=DIALECTS_DB_PATH,
        region_mode='yindian'
):
    """
    ğŸ“Œ ä¸»æ§å‡½æ•¸ï¼šå°èªéŸ³æ¢ä»¶è¼¸å…¥é€²è¡Œç‰¹å¾µåˆ†æï¼Œæ”¯æ´å¤šåœ°é»èˆ‡ç‰¹å¾µæ¬„ä½ã€‚
    å›å‚³ï¼šList of DataFramesï¼ˆæ¯å€‹æ¢ä»¶çš„çµ±è¨ˆçµæœï¼‰
    """
    locations_new = query_dialect_abbreviations(regions, locations, region_mode=region_mode)
    match_results = match_locations_batch(" ".join(locations_new))
    # if not any(res[1] == 1 for res in match_results):
    #     raise HTTPException(status_code=404, detail="ğŸ›‘ æ²’æœ‰ä»»ä½•åœ°é»å®Œå…¨åŒ¹é…ï¼Œçµ‚æ­¢åˆ†æã€‚")
        # print("ğŸ›‘ æ²’æœ‰ä»»ä½•åœ°é»å®Œå…¨åŒ¹é…ï¼Œçµ‚æ­¢åˆ†æã€‚")
        # return []

    unique_abbrs = list({abbr for res in match_results for abbr in res[0]})
    # print(f"\nğŸ“ å®Œå…¨åŒ¹é…åœ°é»ç°¡ç¨±ï¼š{unique_abbrs}")

    if not test_inputs:
        print("â„¹ï¸ inputs ç‚ºç©ºï¼Œè‡ªå‹•æ¨å°æ¢ä»¶å­—ä¸²...")
        conn = sqlite3.connect(db_path_char)
        df_char = pd.read_sql_query("SELECT * FROM characters", conn)
        conn.close()

        auto_inputs = []
        auto_features = []

        for feat in features:
            if feat == "è²æ¯":
                unique_vals = sorted(df_char["æ¯"].dropna().unique())
                auto_inputs.extend([f"{v}æ¯" for v in unique_vals])
                auto_features.extend(["è²æ¯"] * len(unique_vals))

            elif feat == "éŸ»æ¯":
                unique_vals = sorted(df_char["æ”"].dropna().unique())
                auto_inputs.extend([f"{v}æ”" for v in unique_vals])
                auto_features.extend(["éŸ»æ¯"] * len(unique_vals))

            elif feat == "è²èª¿":
                clean_vals = sorted(df_char["æ¸…æ¿"].dropna().unique())
                tone_vals = sorted(df_char["èª¿"].dropna().unique())
                for cv in clean_vals:
                    for tv in tone_vals:
                        auto_inputs.append(f"{cv}{tv}")
                        auto_features.append("è²èª¿")

            else:
                print(f"âš ï¸ æœªæ”¯æŒçš„ç‰¹å¾µé¡å‹ï¼š{feat}ï¼Œç•¥é")

        test_inputs = auto_inputs
        features = auto_features
        # print(test_inputs)
        # print(f"ğŸ”§ ç”¢ç”Ÿè¼¸å…¥æ¢ä»¶ {len(test_inputs)} ç­† â¤ å‰5é …ï¼š{test_inputs[:5]}")

    all_results = []

    if len(features) == 1:
        for user_input in test_inputs:
            print("\n" + "â•" * 60)
            # print(f"ğŸ“˜ğŸ“˜ åˆ†æè¼¸å…¥ï¼š{user_input} å°æ‡‰ç‰¹å¾µï¼š{features[0]}")

            summary = run_status([user_input], db_path=db_path_char)
            # if not summary[1]:  # è¿™é‡Œæ£€æŸ¥ summary ä¸­ç¬¬äºŒä¸ªå…ƒç´ 
            #     raise HTTPException(status_code=404, detail="âŒ è¼¸å…¥çš„ä¸­å¤åœ°ä½ä¸å­˜åœ¨")

            for path_input, chars, multi, path_details in summary:
                if chars is False:
                    print("ğŸ›‘ æŸ¥è©¢å¤±æ•—æˆ–ç„¡æ³•è§£æ")
                    continue

                for result in path_details:
                    path_str = result["path"]
                    path_chars = result["characters"]

                    if not path_chars:
                        continue

                    # print(f"\nğŸ”§ é–‹å§‹åˆ†æã€{path_str}ã€çš„ç‰¹å¾µåˆ†å¸ƒ ({features[0]})...\n")
                    # simplified_input = ''.join(re.findall(r'\[(.*?)\]', path_str))
                    df = query_by_status(path_chars, unique_abbrs, [features[0]], path_str,
                                         db_path=db_path_dialect)

                    all_results.append(df)

    else:
        for user_input, feature in zip(test_inputs, features):
            # print(f"\nğŸ“˜ åˆ†æè¼¸å…¥ï¼š{user_input} å°æ‡‰ç‰¹å¾µï¼š{feature}")

            summary = run_status([user_input], db_path=db_path_char)
            # if not summary[1]:  # è¿™é‡Œæ£€æŸ¥ summary ä¸­ç¬¬äºŒä¸ªå…ƒç´ 
            #     raise HTTPException(status_code=404, detail="âŒ è¼¸å…¥çš„ä¸­å¤åœ°ä½ä¸å­˜åœ¨")

            for path_input, chars, multi, path_details in summary:
                if chars is False:
                    print("ğŸ›‘ æŸ¥è©¢å¤±æ•—æˆ–ç„¡æ³•è§£æ")
                    continue

                for result in path_details:
                    path_str = result["path"]
                    path_chars = result["characters"]

                    if not path_chars:
                        continue

                    # print(f"\nğŸ”§ é–‹å§‹åˆ†æã€{path_str}ã€çš„ç‰¹å¾µåˆ†å¸ƒ ({feature})...\n")
                    # simplified_input = ''.join(re.findall(r'\[(.*?)\]', path_str))
                    df = query_by_status(path_chars, unique_abbrs, [feature], path_str, db_path=db_path_dialect)

                    all_results.append(df)

    return all_results


# é€™å‡½æ•¸æ²’å•¥ç”¨
def extract_unique_values(db_path=CHARACTERS_DB_PATH, table="characters"):
    conn = sqlite3.connect(db_path)
    df = pd.read_sql_query(f"SELECT * FROM {table}", conn)
    conn.close()

    unique_values = {}

    for col in HIERARCHY_COLUMNS:
        if col in df.columns:
            values = df[col].dropna().unique()
            values = sorted(str(v).strip() for v in values if str(v).strip() != "")
            unique_values[col] = values
        else:
            unique_values[col] = []
            print(f"âš ï¸ æ¬„ä½ã€Œ{col}ã€ä¸å­˜åœ¨")

    return unique_values

# if __name__ == "__main__":
#     pd.set_option('display.max_rows', None)
#     pd.set_option('display.max_columns', None)
#     pd.set_option('display.max_colwidth', None)
#     pd.set_option('display.width', 0)
#
#     status_inputs = ["èŸ¹-ç³»ç­‰", "çŸ¥çµ„ä¸‰ ç«¯", "é€šå¼€ä¸‰"]
#     # status_inputs = ["èŸ¹-ç­‰"]
#     locations = ['ä¸œèèåŸ', 'é›²æµ®å¯Œæ—']
#     # features = ['è²æ¯', 'éŸ»æ¯', 'è²èª¿']
#     # regions = ['å°ç¶', 'å„‹å·']
#     regions = [""]
#     features = ['è²æ¯']
#
#     results = sta2pho(locations, regions, features, status_inputs)
#     # print(all_summaries)
#
#     for row in results:
#         print(row)
