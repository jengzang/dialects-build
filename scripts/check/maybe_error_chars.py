import os
import re
import sys
import tkinter as tk
from tkinter import filedialog

from common.config import CHARACTERS_DB_PATH
from source.get_new import extract_all_from_files  # ç»å¯¹å¯¼å…¥
from scripts.check.status_arrange_pho import run_status

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path

import sqlite3
import pandas as pd


def check_get_chars(df, feature, user_input=None):
    # å¦‚æœ test_inputs ç‚ºç©ºï¼Œå¾å­—ç¬¦æ•¸æ“šåº«è‡ªå‹•æ¨å°
    if not user_input:
        # print("â„¹ï¸ inputs ç‚ºç©ºï¼Œè‡ªå‹•æ¨å°æ¢ä»¶å­—ä¸²...")
        db_path_char = CHARACTERS_DB_PATH
        conn = sqlite3.connect(db_path_char)
        df_char = pd.read_sql_query("SELECT * FROM characters", conn)
        conn.close()

        auto_inputs = []
        auto_features = []

        if feature == "å£°æ¯":
            unique_vals = sorted(df_char["æ¯"].dropna().unique())
            auto_inputs.extend([f"{v}æ¯" for v in unique_vals])
            # auto_features.extend(["å£°æ¯"] * len(unique_vals))

        elif feature == "éŸµæ¯":
            unique_vals = sorted(df_char["æ”"].dropna().unique())
            auto_inputs.extend([f"{v}æ”" for v in unique_vals])
            # auto_features.extend(["éŸµæ¯"] * len(unique_vals))

        elif feature == "å£°è°ƒ":
            clean_vals = sorted(df_char["æ¸…æ¿"].dropna().unique())
            tone_vals = sorted(df_char["èª¿"].dropna().unique())
            for cv in clean_vals:
                for tv in tone_vals:
                    auto_inputs.append(f"{cv}{tv}")
                    # auto_features.append("å£°è°ƒ")

        else:
            print(f"âš ï¸ æœªæ”¯æ´çš„ç‰¹å¾µé¡å‹ï¼š{feature}ï¼Œç•¥é")

        # æ›´æ–° test_inputs å’Œ features
        user_input = auto_inputs
    # print(user_input)
    summary = run_status(user_input, db_path=CHARACTERS_DB_PATH)
    all_results = []
    for path_input, chars, multi, path_details in summary:
        if chars is False:
            print("ğŸ›‘ æŸ¥è©¢å¤±æ•—æˆ–ç„¡æ³•è§£æ")
            continue

        for result in path_details:
            path_str = result["path"]
            path_chars = result["characters"]

            if not path_chars:
                continue

            # print(f"\nğŸ”§ é–‹å§‹åˆ†æã€{path_str}ã€çš„ç‰¹å¾µåˆ†å¸ƒ ({feature})...\n")
            simplified_input = ''.join(re.findall(r'\[(.*?)\]', path_str))
            # print(f"å­—åˆ—{path_chars}")
            # print(f"è¼¸å…¥{simplified_input}")
            df_new = check_by_status(path_chars, feature, df, simplified_input)
            if not df_new.empty:
                condition1 = (df_new['å­—æ•¸'] < 2) & (df_new['ä½”æ¯”'] < 0.08)
                condition2 = df_new['ä½”æ¯”'] < 0.03
                filtered_df = df_new[condition1 | condition2]
                all_results.append(filtered_df)
    return all_results


def check_by_status(chars, feature, df, user_input=None):
    """
    æ ¹æ“šæä¾›çš„æ¼¢å­—åå–®ï¼ŒæŸ¥è©¢å…¶åœ¨èªéŸ³ç‰¹å¾µï¼ˆå¦‚è²æ¯/éŸ»æ¯/è²èª¿ï¼‰ä¸‹çš„åˆ†ä½ˆæƒ…æ³ã€‚

    åŠŸèƒ½ï¼š
    - è¨ˆç®—æ¯ç¨®èªéŸ³ç‰¹å¾µå€¼ï¼ˆå¦‚ b, p, m...ï¼‰çš„å­—æ•¸ã€æ¯”ä¾‹ï¼ˆå»é‡å¾Œï¼‰

    è¼¸å‡ºï¼š
    - æ¯ç­†çµ±è¨ˆçµæœä»¥å­—å…¸æ–¹å¼è¼¸å‡ºï¼Œæœ€çµ‚è½‰ç‚º DataFrame
    """

    # çµ±è¨ˆçµæœå­˜æ”¾çš„åˆ—è¡¨
    results = []
    loc_chars_df = df[df["æ±‰å­—"].isin(chars)]
    # print(f"   - åŒ¹é…è¼¸å…¥æ¼¢å­—ç­†æ•¸ï¼š{len(loc_chars_df)} / {len(chars)}")
    total_chars = len(loc_chars_df["æ±‰å­—"].unique())

    feature_groups = loc_chars_df.groupby(feature)

    for fval, sub_df in feature_groups:
        # è·å–æ¯ä¸ªç‰¹å¾å€¼ä¸‹çš„æ‰€æœ‰æ±‰å­—ï¼Œå¹¶å»é‡
        all_chars = sub_df["æ±‰å­—"].tolist()
        unique_chars = list(set(all_chars))
        count = len(unique_chars)

        # è¾“å‡ºæ¯ä¸ªç‰¹å¾å€¼çš„ç»Ÿè®¡ä¿¡æ¯
        results.append({
            "ç‰¹å¾µé¡åˆ¥": feature,
            "ç‰¹å¾µå€¼": user_input,  # ä½¿ç”¨ user_input ä½œä¸ºç‰¹å¾µå€¼
            "åˆ†çµ„å€¼": fval,  # è¿™é‡Œçš„åˆ†ç»„å€¼ç›´æ¥æ˜¯ fvalï¼ˆå³ç‰¹å¾å€¼ï¼‰
            "å­—æ•¸": count,
            "ä½”æ¯”": round(count / total_chars, 4) if total_chars else 0.0,
            "å°æ‡‰å­—": unique_chars,
        })

    # print("\nâœ… åˆ†æå®Œæˆï¼")

    # è¿”å›ç»“æœ DataFrame
    return pd.DataFrame(results)


def select_files():
    # ä½¿ç”¨ tkinter æ‰“é–‹æ–‡ä»¶é¸æ“‡æ¡†ï¼Œå…è¨±é¸æ“‡å¤šå€‹æ–‡ä»¶
    root = tk.Tk()
    root.withdraw()  # éš±è—ä¸»çª—å£
    file_paths = filedialog.askopenfilenames(title="é¸æ“‡æ–‡ä»¶", filetypes=(
        ("Excel æ–‡ä»¶", "*.xls;*.xlsx"), ("TSV æ–‡ä»¶", "*.tsv"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")))

    if not file_paths:
        print("æœªé¸æ“‡ä»»ä½•æ–‡ä»¶")
        return

    # è™•ç†æ¯å€‹é¸ä¸­çš„æ–‡ä»¶
    for file_path in file_paths:
        # èª¿ç”¨æå–è™•ç†å‡½æ•¸ä¸¦å°‡çµæœæ‰“å°åœ¨å‘½ä»¤è¡Œ
        df = extract_all_from_files(file_path)
        results1 = check_get_chars(df, "å£°æ¯")
        results2 = check_get_chars(df, "éŸµæ¯")
        results = results1 + results2
        all_unique_chars = set()
        for result_df in results:
            if not result_df.empty:
                # æå–"å°æ‡‰å­—"åˆ—å¹¶å°†æ‰€æœ‰å­—åˆå¹¶åˆ°ä¸€ä¸ªé›†åˆä¸­
                for chars_list in result_df['å°æ‡‰å­—']:
                    all_unique_chars.update(chars_list)  # å°†æ¯ä¸ªå­—æ·»åŠ åˆ°é›†åˆä¸­

        # å°†é›†åˆè½¬æ¢ä¸ºåˆ—è¡¨ï¼Œå»é‡åçš„å­—å°†æˆä¸ºåˆ—è¡¨çš„å…ƒç´ 
        all_unique_chars_list = list(all_unique_chars)
        # æ‰“å°ç»“æœ
        print(all_unique_chars_list)
        print(len(all_unique_chars_list))
        # æ·»åŠ  "ç°¡ç¨±" åˆ—ï¼Œå†…å®¹æ˜¯å»é™¤åç¼€çš„æ–‡ä»¶å
        # df['ç°¡ç¨±'] = os.path.splitext(os.path.basename(file_path))[0]
        # if 'æ±‰å­—' in df.columns:
        #     df.rename(columns={'æ±‰å­—': 'æ¼¢å­—'}, inplace=True)
        # analyze_characters_from_db()
        pd.set_option('display.max_rows', None)
        pd.set_option('display.max_columns', None)
        pd.set_option('display.max_colwidth', None)
        pd.set_option('display.width', 0)
        # print(f"è™•ç†çµæœ - {file_path}ï¼š")


if __name__ == "__main__":
    select_files()
